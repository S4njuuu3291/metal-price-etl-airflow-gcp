# â˜ï¸ Metal Price Pipeline â€” End-to-End ETL with Airflow & GCP

## ğŸ“˜ Overview

**Metal Price Pipeline** adalah proyek *end-to-end data engineering pipeline* yang dirancang untuk:
- Menarik data harga logam dan nilai tukar mata uang dari API eksternal.
- Melakukan transformasi dan validasi data.
- Menyimpan hasilnya ke **Google BigQuery** sebagai *Data Warehouse*.
- Mengotomatisasi seluruh proses menggunakan **Apache Airflow** di dalam **Docker Compose** environment.

Pipeline ini mencerminkan alur kerja *production-grade ETL* di dunia industri â€” mulai dari data ingestion, processing, sampai analitik-ready data delivery.

---

## ğŸ§© System Architecture
![alt text](img_readme/arsitektur_sistem.png)

## âš™ï¸ Tech Stack

| Layer | Tool | Purpose |
|-------|------|----------|
| **Orchestration** | ğŸŒ€ Apache Airflow | Automasi & scheduling ETL pipeline |
| **Infrastructure** | ğŸ³ Docker Compose | Containerization environment |
| **Cloud Platform** | â˜ï¸ Google Cloud Platform | Target penyimpanan & analitik |
| **Data Lake** | ğŸ—ƒï¸ Google Cloud Storage | Menyimpan file mentah & hasil transformasi |
| **Data Warehouse** | ğŸ§± BigQuery | Menyimpan data terstruktur untuk analisis |
| **Language** | ğŸ Python (Poetry) | Data transformation, validation, dan integration |
| **Logging & Validation** | ğŸ§© Python logging + assertion | Menjaga integritas data antar tahap ETL |

---

## ğŸš€ Pipeline Flow

![airflow_dag](img_readme/airflow_dag.png)  

### DAG: `cloud_metal_price`

| Step | Task ID | Description |
|------|----------|-------------|
| 1ï¸âƒ£ | `extract_from_api` | Ambil data logam & currency dari API eksternal |
| 2ï¸âƒ£ | `load_to_gcs` | Simpan data mentah ke Google Cloud Storage |
| 3ï¸âƒ£ | `transform_data` | Mapping ID, ubah struktur jadi format warehouse |
| 4ï¸âƒ£ | `validate_data` | Validasi field penting (`date`, `price_usd`, `metal_id`) |
| 5ï¸âƒ£ | `load_data` | Insert ke BigQuery tabel fakta `fact_metal_price` dan `fact_currency_rates` |

---

## ğŸ§  Data Model (Dimensional Schema)

![skema_dw](img_readme/skema_dw.png)  


### ğŸ“Š Fact Tables
- `fact_metal_price`  
  - `id`, `date`, `metal_id`, `unit`, `price_usd`
- `fact_currency_rates`  
  - `currency_code`, `date`, `rate_to_usd`

### ğŸ§± Dimension Tables
- `dim_metal`
  - Static mapping (gold â†’ 1, silver â†’ 2, dst.)
- `dim_currency`
  - Referensi kode mata uang

---

## ğŸ§° Key Features

âœ… Modular tasks via PythonOperator  
âœ… XCom data passing antar task  
âœ… Validation sebelum load ke warehouse  
âœ… Error logging terperinci (GCP insert logs)  
âœ… Environment fully containerized  
âœ… GCP integration tested (GCS + BigQuery)  

---

## ğŸ“‚ Project Structure

```

metal-price-pipeline/
â”‚
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ dag_metal_cloud.py              # DAG utama Airflow
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ create_dw.py                    # Pembuatan skema DW di BQ dan insert value tabel dimensi 
â”‚   â”œâ”€â”€ extract_load_gcs.py             # Extract & load ke GCS
â”‚   â”œâ”€â”€ transform_data.py               # Transformasi data API
â”‚   â”œâ”€â”€ validate_data.py                # Validasi hasil transform
â”‚   â””â”€â”€ load_data.py                    # Load ke BigQuery
â”‚
â”œâ”€â”€ docker-compose.yml                  # Airflow + Postgres services
â”œâ”€â”€ requirements.txt / pyproject.toml    # Poetry dependency
â””â”€â”€ README.md

````

---

## ğŸ“¦ Deployment Guide

1ï¸âƒ£ **Build & Start Services**
```bash
docker compose up --build
````

2ï¸âƒ£ **Access Airflow Web UI**

```
http://localhost:8080
```

Username: `airflow`
Password: `airflow`

3ï¸âƒ£ **Trigger DAG**

```bash
airflow dags trigger cloud_metal_price
```

4ï¸âƒ£ **Monitor Progress**

![task_success](img_readme/success_task.png)  

## ğŸ‘¨â€ğŸ’» Author

**Sanjukin Pinem**
ğŸ“ Computer Science, Universitas Padjadjaran
ğŸ’¼ Aspiring Data Engineer | Python | Airflow | GCP | SQL

---